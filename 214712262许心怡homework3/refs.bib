@inbook{recsys_sim_alibaba,
author = {Pi, Qi and Zhou, Guorui and Zhang, Yujing and Wang, Zhe and Ren, Lejian and Fan, Ying and Zhu, Xiaoqiang and Gai, Kun},
title = {Search-Based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412744},
abstract = {Rich user behavior data has been proven to be of great value for click-through rate prediction tasks, especially in industrial applications such as recommender systems and online advertising. Both industry and academy have paid much attention to this topic and propose different approaches to modeling with long sequential user behavior data. Among them, memory network based model MIMN proposed by Alibaba, achieves SOTA with the co-design of both learning algorithm and serving system. MIMN is the first industrial solution that can model sequential user behavior data with length scaling up to 1000. However, MIMN fails to precisely capture user interests given a specific candidate item when the length of user behavior sequence increases further, say, by 10 times or more. This challenge exists widely in previously proposed approaches.In this paper, we tackle this problem by designing a new modeling paradigm, which we name as Search-based Interest Model (SIM). SIM extracts user interests with two cascaded search units: (i) General Search Unit (GSU) acts as a general search from the raw and arbitrary long sequential behavior data, with query information from candidate item, and gets a Sub user Behavior Sequence (SBS) which is relevant to candidate item; (ii) Exact Search Unit (ESU) models the precise relationship between candidate item and SBS. This cascaded search paradigm enables SIM with a better ability to model lifelong sequential behavior data in both scalability and accuracy. Apart from the learning algorithm, we also introduce our hands-on experience on how to implement SIM in large scale industrial systems. Since 2019, SIM has been deployed in the display advertising system in Alibaba, bringing 7.1% CTR and 4.4% RPM lift, which is significant to the business. Serving the main traffic in our real system now, SIM models sequential user behavior data with maximum length reaching up to 54000, pushing SOTA to 54x.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {2685–2692},
numpages = {8}
}


@misc{recsys_dlrm_facebook,
      title={Deep Learning Recommendation Model for Personalization and Recommendation Systems}, 
      author={Maxim Naumov and Dheevatsa Mudigere and Hao-Jun Michael Shi and Jianyu Huang and Narayanan Sundaraman and Jongsoo Park and Xiaodong Wang and Udit Gupta and Carole-Jean Wu and Alisson G. Azzolini and Dmytro Dzhulgakov and Andrey Mallevich and Ilia Cherniavskii and Yinghai Lu and Raghuraman Krishnamoorthi and Ansha Yu and Volodymyr Kondratenko and Stephanie Pereira and Xianjie Chen and Wenlin Chen and Vijay Rao and Bill Jia and Liang Xiong and Misha Smelyanskiy},
      year={2019},
      eprint={1906.00091},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url = {https://arxiv.org/abs/1906.00091},
}

@article{recsys_netflix,
author = {Gomez-Uribe, Carlos A. and Hunt, Neil},
title = {The Netflix Recommender System: Algorithms, Business Value, and Innovation},
year = {2016},
issue_date = {January 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
issn = {2158-656X},
url = {https://doi.org/10.1145/2843948},
doi = {10.1145/2843948},
abstract = {This article discusses the various algorithms that make up the Netflix recommender system, and describes its business purpose. We also describe the role of search and related algorithms, which for us turns into a recommendations problem as well. We explain the motivations behind and review the approach that we use to improve the recommendation algorithms, combining A/B testing focused on improving member retention and medium term engagement, as well as offline experimentation using historical member engagement data. We discuss some of the issues in designing and interpreting A/B tests. Finally, we describe some current areas of focused innovation, which include making our recommender system global and language aware.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = dec,
articleno = {13},
numpages = {19},
keywords = {Recommender systems}
}

@inproceedings{recsys_youtube,
author = {Covington, Paul and Adams, Jay and Sargin, Emre},
title = {Deep Neural Networks for YouTube Recommendations},
year = {2016},
isbn = {9781450340359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2959100.2959190},
doi = {10.1145/2959100.2959190},
abstract = {YouTube represents one of the largest scale and most sophisticated industrial recommendation systems in existence. In this paper, we describe the system at a high level and focus on the dramatic performance improvements brought by deep learning. The paper is split according to the classic two-stage information retrieval dichotomy: first, we detail a deep candidate generation model and then describe a separate deep ranking model. We also provide practical lessons and insights derived from designing, iterating and maintaining a massive recommendation system with enormous user-facing impact.},
booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
pages = {191–198},
numpages = {8},
keywords = {deep learning, recommender system, scalability},
location = {Boston, Massachusetts, USA},
series = {RecSys '16}
}


@InProceedings{recsys_spotify,
author="P{\'e}rez-Marcos, Javier
and L{\'o}pez Batista, Vivian",
editor="De la Prieta, Fernando
and Vale, Zita
and Antunes, Luis
and Pinto, Tiago
and Campbell, Andrew T.
and Juli{\'a}n, Vicente
and Neves, Antonio J.R.
and Moreno, Mar{\'i}a N.",
title="Recommender System Based on Collaborative Filtering for Spotify's Users",
booktitle="Trends in Cyber-Physical Multi-Agent Systems. The PAAMS Collection - 15th International Conference, PAAMS 2017",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="214--220",
abstract="In recent years, with the rise of streaming services like Netflix or Spotify, recommender systems are becoming more and more necessary. The success of Spotify's Discover Weekly, a music recommender system that suggests new songs to users every week, confirms the need to implement these recommender systems. In this paper we propose a methodology based on collaborative filtering to recommend music for Spotify's users from an ordered list of the most played songs over a period of time.",
isbn="978-3-319-61578-3"
}

@inbook{recsys_mobius_baidu,
author = {Fan, Miao and Guo, Jiacheng and Zhu, Shuai and Miao, Shuo and Sun, Mingming and Li, Ping},
title = {MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu's Sponsored Search},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330651},
abstract = {Baidu runs the largest commercial web search engine in China, serving hundreds of millions of online users every day in response to a great variety of queries. In order to build a high-efficiency sponsored search engine, we used to adopt a three-layer funnel-shaped structure to screen and sort hundreds of ads from billions of ad candidates subject to the requirement of low response latency and the restraints of computing resources. Given a user query, the top matching layer is responsible for providing semantically relevant ad candidates to the next layer, while the ranking layer at the bottom concerns more about business indicators (e.g., CPM, ROI, etc.) of those ads. The clear separation between the matching and ranking objectives results in a lower commercial return. The Mobius project has been established to address this serious issue. It is our first attempt to train the matching layer to consider CPM as an additional optimization objective besides the query-ad relevance, via directly predicting CTR (click-through rate) from billions of query-ad pairs. Specifically, this paper will elaborate on how we adopt active learning to overcome the insufficiency of click history at the matching layer when training our neural click networks offline, and how we use the SOTA ANN search technique for retrieving ads more efficiently (Here "ANN'' stands for approximate nearest neighbor search). We contribute the solutions to Mobius-V1 as the first version of our next generation query-ad matching system.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2509–2517},
numpages = {9}
}

@inbook{recsys_baidu_aibox,
author = {Zhao, Weijie and Zhang, Jingyuan and Xie, Deping and Qian, Yulei and Jia, Ronglai and Li, Ping},
title = {AIBox: CTR Prediction Model Training on a Single Node},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3358045},
abstract = {As one of the major search engines in the world, Baidu's Sponsored Search has long adopted the use of deep neural network (DNN) models for Ads click-through rate (CTR) predictions, as early as in 2013. The input futures used by Baidu's online advertising system (a.k.a. "Phoenix Nest'') are extremely high-dimensional (e.g., hundreds or even thousands of billions of features) and also extremely sparse. The size of the CTR models used by Baidu's production system can well exceed 10TB. This imposes tremendous challenges for training, updating, and using such models in production. For Baidu's Ads system, it is obviously important to keep the model training process highly efficient so that engineers (and researchers) are able to quickly refine and test their new models or new features. Moreover, as billions of user ads click history entries are arriving every day, the models have to be re-trained rapidly because CTR prediction is an extremely time-sensitive task. Baidu's current CTR models are trained on MPI (Message Passing Interface) clusters, which require high fault tolerance and synchronization that incur expensive communication and computation costs. And, of course, the maintenance costs for clusters are also substantial. This paper presents AIBox, a centralized system to train CTR models with tens-of-terabytes-scale parameters by employing solid-state drives (SSDs) and GPUs. Due to the memory limitation on GPUs, we carefully partition the CTR model into two parts: one is suitable for CPUs and another for GPUs. We further introduce a bi-level cache management system over SSDs to store the 10TB parameters while providing low-latency accesses. Extensive experiments on production data reveal the effectiveness of the new system. AIBox has comparable training performance with a large MPI cluster, while requiring only a small fraction of the cost for the cluster.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {319–328},
numpages = {10}
}

@inbook{recsys_mimn_alibaba,
author = {Pi, Qi and Bian, Weijie and Zhou, Guorui and Zhu, Xiaoqiang and Gai, Kun},
title = {Practice on Long Sequential User Behavior Modeling for Click-Through Rate Prediction},
year = {2019},
isbn = {9781450362016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3292500.3330666},
abstract = {Click-through rate (CTR) prediction is critical for industrial applications such as recommender system and online advertising. Practically, it plays an important role for CTR modeling in these applications by mining user interest from rich historical behavior data. Driven by the development of deep learning, deep CTR models with ingeniously designed architecture for user interest modeling have been proposed, bringing remarkable improvement of model performance over offline metric. However, great efforts are needed to deploy these complex models to online serving system for realtime inference, facing massive traffic request. Things turn to be more difficult when it comes to long sequential user behavior data, as the system latency and storage cost increase approximately linearly with the length of user behavior sequence.In this paper, we face directly the challenge of long sequential user behavior modeling and introduce our hands-on practice with the co-design of machine learning algorithm and online serving system for CTR prediction task. (i) From serving system view, we decouple the most resource-consuming part of user interest modeling from the entire model by designing a separate module named UIC (User Interest Center). UIC maintains the latest interest state for each user, whose update depends on realtime user behavior trigger event, rather than on traffic request. Hence UIC is latency free for realtime CTR prediction. (ii) From machine learning algorithm view, we propose a novel memory-based architecture named MIMN (Multi-channel user Interest Memory Network) to capture user interests from long sequential behavior data, achieving superior performance over state-of-the-art models. MIMN is implemented in an incremental manner with UIC module.Theoretically, the co-design solution of UIC and MIMN enables us to handle the user interest modeling with unlimited length of sequential behavior data. Comparison between model performance and system efficiency proves the effectiveness of proposed solution. To our knowledge, this is one of the first industrial solutions that are capable of handling long sequential user behavior data with length scaling up to thousands. It now has been deployed in the display advertising system in Alibaba.},
booktitle = {Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining},
pages = {2671–2679},
numpages = {9}
}

@inbook{recsys_sim_alibaba,
author = {Pi, Qi and Zhou, Guorui and Zhang, Yujing and Wang, Zhe and Ren, Lejian and Fan, Ying and Zhu, Xiaoqiang and Gai, Kun},
title = {Search-Based User Interest Modeling with Lifelong Sequential Behavior Data for Click-Through Rate Prediction},
year = {2020},
isbn = {9781450368599},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340531.3412744},
abstract = {Rich user behavior data has been proven to be of great value for click-through rate prediction tasks, especially in industrial applications such as recommender systems and online advertising. Both industry and academy have paid much attention to this topic and propose different approaches to modeling with long sequential user behavior data. Among them, memory network based model MIMN proposed by Alibaba, achieves SOTA with the co-design of both learning algorithm and serving system. MIMN is the first industrial solution that can model sequential user behavior data with length scaling up to 1000. However, MIMN fails to precisely capture user interests given a specific candidate item when the length of user behavior sequence increases further, say, by 10 times or more. This challenge exists widely in previously proposed approaches.In this paper, we tackle this problem by designing a new modeling paradigm, which we name as Search-based Interest Model (SIM). SIM extracts user interests with two cascaded search units: (i) General Search Unit (GSU) acts as a general search from the raw and arbitrary long sequential behavior data, with query information from candidate item, and gets a Sub user Behavior Sequence (SBS) which is relevant to candidate item; (ii) Exact Search Unit (ESU) models the precise relationship between candidate item and SBS. This cascaded search paradigm enables SIM with a better ability to model lifelong sequential behavior data in both scalability and accuracy. Apart from the learning algorithm, we also introduce our hands-on experience on how to implement SIM in large scale industrial systems. Since 2019, SIM has been deployed in the display advertising system in Alibaba, bringing 7.1% CTR and 4.4% RPM lift, which is significant to the business. Serving the main traffic in our real system now, SIM models sequential user behavior data with maximum length reaching up to 54000, pushing SOTA to 54x.},
booktitle = {Proceedings of the 29th ACM International Conference on Information &amp; Knowledge Management},
pages = {2685–2692},
numpages = {8}
}



@INPROCEEDINGS{recsys_archimp_facebook_hpca20,  
author={U. {Gupta} and C. {Wu} and X. {Wang} and M. {Naumov} and B. {Reagen} and D. {Brooks} and B. {Cottel} and K. {Hazelwood} and M. {Hempstead} and B. {Jia} and H. S. {Lee} and A. {Malevich} and D. {Mudigere} and M. {Smelyanskiy} and L. {Xiong} and X. {Zhang}},  
booktitle={2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)},   
title={The Architectural Implications of Facebook's DNN-Based Personalized Recommendation},   
year={2020},  
volume={},  
number={},  
pages={488-501},  
doi={10.1109/HPCA47549.2020.00047}
}



@INPROCEEDINGS{recsys_traineff_facebook_hpca21,  
author={B. {Acun} and M. {Murphy} and X. {Wang} and J. {Nie } and C. {Wu} and K. {Hazelwood } },  
booktitle={2021 IEEE International Symposium on High Performance Computer Architecture (HPCA)},   
title={Understanding Training Efficiency of Deep Learning Recommendation Models at Scale},   
year={2021},  
volume={},  
number={},  
pages={xxx-xxx},  
doi={}
}


@inbook{recsys_deeprecsys_facebook_isca20,
author = {Gupta, Udit and Hsia, Samuel and Saraph, Vikram and Wang, Xiaodong and Reagen, Brandon and Wei, Gu-Yeon and Lee, Hsien-Hsin S. and Brooks, David and Wu, Carole-Jean},
title = {DeepRecSys: A System for Optimizing End-to-End at-Scale Neural Recommendation Inference},
year = {2020},
isbn = {9781728146614},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISCA45697.2020.00084},
abstract = {Neural personalized recommendation is the cornerstone of a wide collection of cloud services and products, constituting significant compute demand of cloud infrastructure. Thus, improving the execution efficiency of recommendation directly translates into infrastructure capacity saving. In this paper, we propose DeepRecSched, a recommendation inference scheduler that maximizes latency-bounded throughput by taking into account characteristics of inference query size and arrival patterns, model architectures, and underlying hardware systems. By carefully optimizing task versus data-level parallelism, DeepRecSched improves system throughput on server class CPUs by 2x across eight industry-representative models. Next, we deploy and evaluate this optimization in an at-scale production datacenter which reduces end-to-end tail latency across a wide variety of recommendation models by 30%. Finally, DeepRecSched demonstrates the role and impact of specialized AI hardware in optimizing system level performance (QPS) and power efficiency (QPS/watt) of recommendation inference.In order to enable the design space exploration of customized recommendation systems shown in this paper, we design and validate an end-to-end modeling infrastructure, DeepRecInfra. DeepRecInfra enables studies over a variety of recommendation use cases, taking into account at-scale effects, such as query arrival patterns and recommendation query sizes, observed from a production datacenter, as well as industry-representative models and tail latency targets.},
booktitle = {Proceedings of the ACM/IEEE 47th Annual International Symposium on Computer Architecture},
pages = {982–995},
numpages = {14}
}


@inproceedings{recacc_tensordimm_kaist_micro19,
author = {Kwon, Youngeun and Lee, Yunjae and Rhu, Minsoo},
title = {TensorDIMM: A Practical Near-Memory Processing Architecture for Embeddings and Tensor Operations in Deep Learning},
year = {2019},
isbn = {9781450369381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3352460.3358284},
doi = {10.1145/3352460.3358284},
abstract = {Recent studies from several hyperscalars pinpoint to embedding layers as the most memory-intensive deep learning (DL) algorithm being deployed in today's datacenters. This paper addresses the memory capacity and bandwidth challenges of embedding layers and the associated tensor operations. We present our vertically integrated hardware/software co-design, which includes a custom DIMM module enhanced with near-memory processing cores tailored for DL tensor operations. These custom DIMMs are populated inside a GPU-centric system interconnect as a remote memory pool, allowing GPUs to utilize for scalable memory bandwidth and capacity expansion. A prototype implementation of our proposal on real DL systems shows an average 6.2-17.6\texttimes{} performance improvement on state-of-the-art DNN-based recommender systems.},
booktitle = {Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {740–753},
numpages = {14},
keywords = {machine learning, System architecture, graphics processing unit (GPU), neural processing unit (NPU), near-memory processing, memory architecture, neural network, DIMM},
location = {Columbus, OH, USA},
series = {MICRO '52}
}

@INPROCEEDINGS{recacc_recnmp_facebook_isca20,
  author={L. {Ke} and U. {Gupta} and B. Y. {Cho} and D. {Brooks} and V. {Chandra} and U. {Diril} and A. {Firoozshahian} and K. {Hazelwood} and B. {Jia} and H. S. {Lee} and M. {Li} and B. {Maher} and D. {Mudigere} and M. {Naumov} and M. {Schatz} and M. {Smelyanskiy} and X. {Wang} and B. {Reagen} and C. {Wu} and M. {Hempstead} and X. {Zhang}},
  booktitle={2020 ACM/IEEE 47th Annual International Symposium on Computer Architecture (ISCA)}, 
  title={RecNMP: Accelerating Personalized Recommendation with Near-Memory Processing}, 
  year={2020},
  volume={},
  number={},
  pages={790-803},
  abstract={Personalized recommendation systems leverage deep learning models and account for the majority of data center AI cycles. Their performance is dominated by memory-bound sparse embedding operations with unique irregular memory access patterns that pose a fundamental challenge to accelerate. This paper proposes a lightweight, commodity DRAM compliant, near-memory processing solution to accelerate personalized recommendation inference. The in-depth characterization of production-grade recommendation models shows that embedding operations with high model-, operator and data-level parallelism lead to memory bandwidth saturation, limiting recommendation inference performance. We propose RecNMP which provides a scalable solution to improve system throughput, supporting a broad range of sparse embedding models. RecNMP is specifically tailored to production environments with heavy co-location of operators on a single server. Several hardware/software cooptimization techniques such as memory-side caching, tableaware packet scheduling, and hot entry profiling are studied, providing up to 9.8× memory latency speedup over a highly-optimized baseline. Overall, RecNMP offers 4.2× throughput improvement and 45.8% memory energy savings.},
  keywords={cache storage;DRAM chips;learning (artificial intelligence);recommender systems;storage management;sparse embedding models;RecNMP;memory-side caching;throughput improvement;memory energy savings;data center AI cycles;memory-bound sparse embedding operations;memory access patterns;lightweight commodity DRAM compliant;near-memory processing solution;personalized recommendation inference;production-grade recommendation models;operatorand data-level parallelism lead;memory bandwidth saturation;recommendation inference performance;system throughput;high model-level parallelism;deep learning;commodity DRAM compliant;hardware/software cooptimization},
  doi={10.1109/ISCA45697.2020.00070},
  ISSN={},
  month={May},}


@INPROCEEDINGS{recacc_tensorcasting_kaist_hpca21,  
author={Y. {Kwon} and Y. {Lee} and M. {Rhu} },  
booktitle={2021 IEEE International Symposium on High Performance Computer Architecture (HPCA)},   
title={Tensor Casting: Co-Designing Algorithm-Architecture for Personalized Recommendation Training},   
year={2021},  
volume={},  
number={},  
pages={xxx-xxx},  
doi={}
}

@INPROCEEDINGS{recacc_recssd_kaist_asplos21,  
author={M. {Wilkening} and U. {Gupta} and S. {Hsia}  and C. {Trippel} and C. {Wu} and D. {Brooks} and G. {Wei}},  
booktitle={2021 International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)},   
title={RecSSD: Near Data Processing for Solid State Drive Based Recommendation Inference},   
year={2021},  
volume={},  
number={},  
pages={xxx-xxx},  
doi={}
}

@INPROCEEDINGS{recacc_fafnir_hpca21,  
author={Y. {Kwon} and Y. {Lee} and M. {Rhu} },  
booktitle={2021 IEEE International Symposium on High Performance Computer Architecture (HPCA)},   
title={Tensor Casting: Co-Designing Algorithm-Architecture for Personalized Recommendation Training},   
year={2021},  
volume={},  
number={},  
pages={xxx-xxx},  
doi={}
}


@inproceedings{recsys_bst_alibaba,
author = {Chen, Qiwei and Zhao, Huan and Li, Wei and Huang, Pipei and Ou, Wenwu},
title = {Behavior Sequence Transformer for E-Commerce Recommendation in Alibaba},
year = {2019},
isbn = {9781450367837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3326937.3341261},
doi = {10.1145/3326937.3341261},
abstract = {Deep learning based methods have been widely used in industrial recommendation systems (RSs). Previous works adopt an Embedding&amp;MLP paradigm: raw features are embedded into low-dimensional vectors, which are then fed on to MLP for final recommendations. However, most of these works just concatenate different features, ignoring the sequential nature of users' behaviors. In this paper, we propose to use the powerful Transformer model to capture the sequential signals underlying users' behavior sequences for recommendation in Alibaba. Experimental results demonstrate the superiority of the proposed model, which is then deployed online at Taobao and obtain significant improvements in online Click-Through-Rate (CTR) comparing to two baselines.},
booktitle = {Proceedings of the 1st International Workshop on Deep Learning Practice for High-Dimensional Sparse Data},
articleno = {12},
numpages = {4},
location = {Anchorage, Alaska},
series = {DLP-KDD '19}
}


@MISC{cacti6,
    author = {Naveen Muralimanohar and Rajeev Balasubramonian},
    title = {CACTI 6.0: A Tool to Understand Large Caches},
    year = {}
}

@misc{recsys_trainfb_facebook,
      title={Deep Learning Training in Facebook Data Centers: Design of Scale-up and Scale-out Systems}, 
      author={Maxim Naumov and John Kim and Dheevatsa Mudigere and Srinivas Sridharan and Xiaodong Wang and Whitney Zhao and Serhat Yilmaz and Changkyu Kim and Hector Yuen and Mustafa Ozdal and Krishnakumar Nair and Isabel Gao and Bor-Yiing Su and Jiyan Yang and Mikhail Smelyanskiy},
      year={2020},
      eprint={2003.09518},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url = {https://arxiv.org/pdf/2003.09518}
}

@misc{recsys_inffb_facebook,
      title={Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications}, 
      author={Jongsoo Park and Maxim Naumov and Protonu Basu and Summer Deng and Aravind Kalaiah and Daya Khudia and James Law and Parth Malani and Andrey Malevich and Satish Nadathur and Juan Pino and Martin Schatz and Alexander Sidorov and Viswanath Sivakumar and Andrew Tulloch and Xiaodong Wang and Yiming Wu and Hector Yuen and Utku Diril and Dmytro Dzhulgakov and Kim Hazelwood and Bill Jia and Yangqing Jia and Lin Qiao and Vijay Rao and Nadav Rotem and Sungjoo Yoo and Mikhail Smelyanskiy},
      year={2018},
      eprint={1811.09886},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/pdf/1811.09886}
}


@inproceedings{recsys_billionscale_alibaba,
author = {Wang, Jizhe and Huang, Pipei and Zhao, Huan and Zhang, Zhibo and Zhao, Binqiang and Lee, Dik Lun},
title = {Billion-Scale Commodity Embedding for E-Commerce Recommendation in Alibaba},
year = {2018},
isbn = {9781450355520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3219819.3219869},
doi = {10.1145/3219819.3219869},
booktitle = {Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {839–848},
numpages = {10},
keywords = {e-commerce recommendation, collaborative filtering, recommendation system, graph embedding},
location = {London, United Kingdom},
series = {KDD'18}
}




















@book{lamport94,
 author = "Leslie Lamport",
 title = "{\LaTeX: A Document Preparation System}",
 year = "1994",
 publisher = "Addison-Wesley",
 edition = "2nd",
 address = "Reading, Massachusetts"
}

@inproceedings{nicepaper1,
  author = "Firstname1 Lastname1 and Firstname2 Lastname2",
  title = "A Very Nice Paper To Cite",
  year = "2016",
  booktitle = "Proceedings of the 49th Annual IEEE/ACM International Symposium on Microarchitecture"
}

@inproceedings{nicepaper2,
  author = "Firstname1 Lastname1 and Firstname2 Lastname2 and Firstname3 Lastname3",
  title = "Another Very Nice Paper to Cite",
  year = "2015",
  booktitle = "Proceedings of the 48th Annual IEEE/ACM International Symposium on Microarchitecture"
}

@inproceedings{nicepaper3,
  author = "Firstname1 Lastname1 and Firstname2 Lastname2 and Firstname3 Lastname3 and Firstname4 Lastname4 and Firstname5 Lastname5 and Firstname6 Lastname6 and Firstname7 Lastname7 and Firstname8 Lastname8 and Firstname9 Lastname9 and Firstname10 Lastname10 and Firstname11 Lastname11 and Firstname12 Lastname12",
  title = "Yet Another Very Nice Paper To Cite, With Many Author Names All Spelled Out",
  year = "2011",
  booktitle = "Proceedings of the 38th Annual International Symposium on Computer Architecture"
}
